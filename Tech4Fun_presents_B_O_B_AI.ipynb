{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGngMqiJhxO6",
        "outputId": "658c0415-649e-40d5-cdc8-81f99ddf5ebf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/david8862/keras-YOLOv3-model-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUiie60Qh2xh",
        "outputId": "432c9913-08da-418a-df8b-a9922b4223dd"
      },
      "outputs": [],
      "source": [
        "%cd ./keras-YOLOv3-model-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -O weights/yolov3.weights https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget -O weights/yolov3-tiny.weights https://pjreddie.com/media/files/yolov3-tiny.weights\n",
        "!python tools/model_converter/convert.py cfg/yolov3.cfg weights/yolov3.weights weights/yolov3.h5\n",
        "!python tools/model_converter/convert.py cfg/yolov3-tiny.cfg weights/yolov3-tiny.weights weights/yolov3-tiny.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0bqFqHENkHE2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "import copy\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import ReLU, Activation, Multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAxeTvP_kiTm"
      },
      "outputs": [],
      "source": [
        "def VOCtoCSV(dataset_dir, annotation_dir):\n",
        "  \"\"\"\n",
        "  Convert PASCAL VOC annotations to a CSV file format.\n",
        "  Args:\n",
        "  dataset_dir : str : directory path where dataset is present\n",
        "  annotation_dir : str : directory path where annotations are present\n",
        "  Returns:\n",
        "  None\n",
        "\n",
        "  Outputs:\n",
        "  annotations.txt : CSV file with following format:\n",
        "                    dataset_dir/subfolder/image_filename x1_min,y1_min,x1_max,y1_max,class_id1 x2_min,y2_min,x2_max,y2_max,class_id2 ...\n",
        "  classes.txt : List of all the classes in the annotations\n",
        "  \"\"\"\n",
        "  # open a CSV file to write the data to\n",
        "  with open(os.path.join(dataset_dir, 'annotations.txt'), 'w', newline='') as f:\n",
        "      writer = csv.writer(f, delimiter=\" \", escapechar=',')\n",
        "      # write the header row to the CSV file\n",
        "      #writer.writerow(['image_name', 'xmin', 'ymin', 'xmax', 'ymax', 'class'])\n",
        "\n",
        "      labels = []\n",
        "\n",
        "      # iterate through the subfolders in the dataset directory\n",
        "      for subfolder in os.listdir(dataset_dir):\n",
        "          if subfolder.startswith('sequence_'):\n",
        "              # Extract the sequence number from the subfolder name\n",
        "              sequence_num = subfolder.split('_')[1]\n",
        "              # Load the corresponding XML file from the annotation folder\n",
        "              xml_file = os.path.join(annotation_dir, 'annotation_s{}.xml'.format(sequence_num))\n",
        "              tree = ET.parse(xml_file)\n",
        "              root = tree.getroot()\n",
        "              for image in root.findall('images/image'):\n",
        "                image_filename = image.attrib.get('file')\n",
        "                # Find all the box elements in the XML file\n",
        "                boxes = []\n",
        "                for box in image.findall(f'box'):\n",
        "                    # Extract the class label\n",
        "                    class_label = box.find('label').text\n",
        "                    if class_label not in labels:\n",
        "                      labels.append(class_label)\n",
        "\n",
        "                    # Extract the bounding box coordinates\n",
        "                    xmin = box.attrib.get('left')\n",
        "                    ymin = box.attrib.get('top')\n",
        "                    xmax = int(xmin) + int(box.attrib.get('width'))\n",
        "                    ymax = int(ymin) + int(box.attrib.get('height'))\n",
        "                    boxes.append(','.join([str(xmin), str(ymin), str(xmax), str(ymax), str(labels.index(class_label))]))\n",
        "                # Write the data to a row in the CSV file\n",
        "                #writer.writerow([dataset_dir+'/'+subfolder+'/'+image_filename, str(' '.join(boxes))])\n",
        "                f.write(' '.join([dataset_dir+'/'+subfolder+'/'+image_filename, str(' '.join(boxes))]) + '\\n')\n",
        "\n",
        "      with open(os.path.join(dataset_dir, 'classes.txt'), 'w') as l:\n",
        "        for label in labels:\n",
        "          l.write(label+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQzmr3V8pwLr"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/drive/MyDrive/RabbitHole/data'\n",
        "annotation_dir = '/content/drive/MyDrive/RabbitHole/data/annotation'\n",
        "\n",
        "VOCtoCSV(dataset_dir, annotation_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHIpOKdXp_SZ"
      },
      "outputs": [],
      "source": [
        "def plot_show_image_with_boxes(image_path, boxes_list):\n",
        "  \"\"\"\n",
        "  Plot and display an image with bounding boxes.\n",
        "  Args:\n",
        "  image_path : str : path to the image\n",
        "  boxes_list : List[str] : List of strings with each string containing bounding box coordinates in the format 'xmin,ymin,xmax,ymax,classid'\n",
        "  Returns:\n",
        "  None\n",
        "  Outputs:\n",
        "  Image is displayed with bounding boxes drawn on it\n",
        "  \"\"\"\n",
        "  # read image\n",
        "  image = cv2.imread(image_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # plot boxes\n",
        "  for i in range(len(boxes_list)):\n",
        "    xmin, ymin, xmax, ymax, classid = boxes_list[i].split(',')\n",
        "    image = cv2.rectangle(image,(int(xmin),int(ymin)),(int(xmax),int(ymax)),(255,0,0), 5)\n",
        "\n",
        "  plt.imshow(image)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "e-DrnjS_qJvK",
        "outputId": "62532b02-70d0-4a2f-cda5-bd25f10ef15e"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = '/content/drive/MyDrive/RabbitHole/data/sequence_1/frame_s1_1.jpg'\n",
        "ANNOTATIONS_PATH = '/content/drive/MyDrive/RabbitHole/data/annotations.txt'\n",
        "\n",
        "with open(ANNOTATIONS_PATH) as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "  for line in lines:\n",
        "\n",
        "    line = line.split(' ')\n",
        "\n",
        "    if line[0] == IMAGE_PATH:\n",
        "      plot_show_image_with_boxes(image_path=line[0],\n",
        "                                 boxes_list=line[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmEybzhXqehL",
        "outputId": "aba4df39-eb6f-42b6-e725-5a934e3742f1"
      },
      "outputs": [],
      "source": [
        "class_counts = {}\n",
        "\n",
        "with open('/content/drive/MyDrive/RabbitHole/data/annotations.txt', 'r') as f:\n",
        "    reader = csv.reader(f, delimiter=' ')\n",
        "    for row in reader:\n",
        "        for box in row[1:]:\n",
        "            class_id = box.split(',')[-1]\n",
        "            if class_id in class_counts:\n",
        "                class_counts[class_id] += 1\n",
        "            else:\n",
        "                class_counts[class_id] = 1\n",
        "\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9PLuibRqkzC"
      },
      "outputs": [],
      "source": [
        "def train_valid_split(file_path, output_path, split_percentage=0.8, shuffle_flag=True):\n",
        "  \"\"\"\n",
        "  Split a file into train and validation sets.\n",
        "  Args:\n",
        "  file_path : str : path to the file that needs to be split\n",
        "  output_path : str : path to the directory where the train and validation files will be saved\n",
        "  split_percentage : float : percentage of data to be used for training, default value is 0.8\n",
        "  shuffle_flag : bool : flag to shuffle the data before splitting, default value is True\n",
        "  Returns:\n",
        "  None\n",
        "  Outputs:\n",
        "  train.txt : file containing training data\n",
        "  valid.txt : file containing validation data\n",
        "  \"\"\"\n",
        "  with open(file_path, 'r') as f:\n",
        "      lines = f.readlines()\n",
        "  if shuffle_flag:\n",
        "      random.shuffle(lines)\n",
        "  split_index = int(len(lines) * split_percentage)\n",
        "  train_lines = lines[:split_index]\n",
        "  valid_lines = lines[split_index:]\n",
        "  with open(f'{output_path}/train.txt', 'w') as f:\n",
        "      f.writelines(train_lines)\n",
        "  with open(f'{output_path}/valid.txt', 'w') as f:\n",
        "      f.writelines(valid_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAJFpYnwqyKO"
      },
      "outputs": [],
      "source": [
        "train_valid_split('/content/drive/MyDrive/RabbitHole/data/annotations.txt',\n",
        "                  '/content/drive/MyDrive/RabbitHole/data',\n",
        "                  0.8, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv0412D8r8YI"
      },
      "source": [
        "Pré treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqVST6M6q6J6",
        "outputId": "a7c8d563-e6fa-416a-de30-85ed806867a9"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/RabbitHole/keras-YOLOv3-model-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds9B2pACsM3n",
        "outputId": "f36209cf-da3a-4773-b40e-6e575eae3885"
      },
      "outputs": [],
      "source": [
        "!apt install --allow-change-held-packages libcudnn8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRL11iZwHWXP",
        "outputId": "e9caee62-be47-4a83-f6d4-8723b8a8da88"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/RabbitHole/keras-YOLOv3-model-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09q3kVAyHt3z",
        "outputId": "e2134a76-9aa0-40a1-86c1-b3e46409c27b"
      },
      "outputs": [],
      "source": [
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsJcGp4ns2tp",
        "outputId": "d7ad5832-889c-43d1-bc2b-dd5043028008"
      },
      "outputs": [],
      "source": [
        "!python train.py --model_type=yolo3_mobilenet_lite \\\n",
        "--anchors_path=configs/yolo3_anchors.txt \\\n",
        "--annotation_file=/content/drive/MyDrive/RabbitHole/data/train.txt \\\n",
        "--classes_path=/content/drive/MyDrive/RabbitHole/data/classes.txt \\\n",
        "--eval_online \\\n",
        "--save_eval_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j7WrSE6tt8G",
        "outputId": "afaffdf5-86d9-4f52-b7fc-d75b277ec7d1"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/drive/MyDrive/RabbitHole/output/yolo3_mobilenet_lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypCPRXInu7Bv",
        "outputId": "9c725203-1c7f-4803-a655-d0ff4437aeaa"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/RabbitHole/keras-YOLOv3-model-set/logs/000/ep020-loss7.758-val_loss7.674-mAP62.063.h5 \\\n",
        "/content/drive/MyDrive/RabbitHole/output/yolo3_mobilenet_lite/trained_final.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WMQ43hqwJQY",
        "outputId": "611e854f-a7f6-4147-d75a-584f46a38de9"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/RabbitHole/keras-YOLOv3-model-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaTzqiuNwOdn",
        "outputId": "14c1d361-4e8e-45a3-e40c-e4e12c76df8e"
      },
      "outputs": [],
      "source": [
        "!python yolo.py \\\n",
        "--model_type=yolo3_mobilenet_lite \\\n",
        "--weights_path=/content/drive/MyDrive/RabbitHole/output/yolo3_mobilenet_lite/trained_final.h5 \\\n",
        "--anchors_path=configs/yolo3_anchors.txt \\\n",
        "--classes_path=/content/drive/MyDrive/RabbitHole/data/classes.txt \\\n",
        "--model_input_shape=416x416 \\\n",
        "--dump_model \\\n",
        "--output_model_file=/content/drive/MyDrive/RabbitHole/output/yolo3_mobilenet_lite/yolo3_mobilenet_lite.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLVm5FtpwSdt",
        "outputId": "2debedeb-4b74-4420-d889-797c8ffa14a1"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRcq5KscKV0c",
        "outputId": "6fe55a9c-bb72-4808-d021-2bf0c9a2f675"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uth9EoVwtaG",
        "outputId": "2de281a9-c63a-430a-f3e2-448831ae2085"
      },
      "outputs": [],
      "source": [
        "!pip install onnxruntime\n",
        "!pip install numpy==1.24.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idR6kO6eyOUA"
      },
      "outputs": [],
      "source": [
        "def load_eval_model(model_path):\n",
        "    # support of tflite model\n",
        "    if model_path.endswith('.tflite'):\n",
        "        from tensorflow.lite.python import interpreter as interpreter_wrapper\n",
        "        model = interpreter_wrapper.Interpreter(model_path=model_path)\n",
        "        model.allocate_tensors()\n",
        "        model_format = 'TFLITE'\n",
        "\n",
        "    # normal keras h5 model\n",
        "    elif model_path.endswith('.h5'):\n",
        "        custom_object_dict = get_custom_objects()\n",
        "\n",
        "        model = load_model(model_path, compile=False, custom_objects=custom_object_dict)\n",
        "        model_format = 'H5'\n",
        "        K.set_learning_phase(0)\n",
        "    else:\n",
        "        raise ValueError('invalid model file')\n",
        "\n",
        "    return model, model_format\n",
        "\n",
        "def get_custom_objects():\n",
        "    '''\n",
        "    form up a custom_objects dict so that the customized\n",
        "    layer/function call could be correctly parsed when keras\n",
        "    .h5 model is loading or converting\n",
        "    '''\n",
        "    custom_objects_dict = {\n",
        "        'tf': tf,\n",
        "        'swish': swish,\n",
        "        'hard_sigmoid': hard_sigmoid,\n",
        "        'hard_swish': hard_swish,\n",
        "        'mish': mish\n",
        "    }\n",
        "\n",
        "    return custom_objects_dict\n",
        "\n",
        "def swish(x):\n",
        "    \"\"\"Swish activation function.\n",
        "    # Arguments\n",
        "        x: Input tensor.\n",
        "    # Returns\n",
        "        The Swish activation: `x * sigmoid(x)`.\n",
        "    # References\n",
        "        [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        try:\n",
        "            # The native TF implementation has a more\n",
        "            # memory-efficient gradient implementation\n",
        "            return K.tf.nn.swish(x)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "    return x * K.sigmoid(x)\n",
        "\n",
        "def hard_sigmoid(x):\n",
        "    return ReLU(6.)(x + 3.) * (1. / 6.)\n",
        "\n",
        "def hard_swish(x):\n",
        "    return Multiply()([Activation(hard_sigmoid)(x), x])\n",
        "\n",
        "def mish(x):\n",
        "    return x * K.tanh(K.softplus(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31Ms_RgkzLUI"
      },
      "outputs": [],
      "source": [
        "def yolo_predict_tflite(interpreter, image, anchors, num_classes, conf_threshold):#, elim_grid_sense, v5_decode):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    #print(\"input/output details:\")\n",
        "    #print(input_details)\n",
        "    #print(output_details)\n",
        "\n",
        "    # check the type of the input tensor\n",
        "    #if input_details[0]['dtype'] == np.float32:\n",
        "        #floating_model = True\n",
        "\n",
        "    height = input_details[0]['shape'][1]\n",
        "    width = input_details[0]['shape'][2]\n",
        "    model_input_shape = (height, width)\n",
        "\n",
        "    image_data = preprocess_image(image, model_input_shape)\n",
        "    #origin image shape, in (height, width) format\n",
        "    image_shape = image.size[::-1]\n",
        "    #print(f\"image shape: {image_shape}\")\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], image_data)\n",
        "    start = time.time()\n",
        "    interpreter.invoke()\n",
        "    print('Time for inference:',time.time()-start)\n",
        "\n",
        "    prediction = []\n",
        "    for output_detail in output_details:\n",
        "        output_data = interpreter.get_tensor(output_detail['index'])\n",
        "        prediction.append(output_data)\n",
        "        #print(f\"output data: {output_data}\")\n",
        "\n",
        "    #if len(anchors) == 5:\n",
        "    #    # YOLOv2 use 5 anchors and have only 1 prediction\n",
        "    #    assert len(prediction) == 1, 'invalid YOLOv2 prediction number.'\n",
        "    #    pred_boxes, pred_classes, pred_scores = yolo2_postprocess_np(prediction[0], image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=conf_threshold, elim_grid_sense=elim_grid_sense)\n",
        "    #else:\n",
        "    #    if v5_decode:\n",
        "    #        pred_boxes, pred_classes, pred_scores = yolo5_postprocess_np(prediction, image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=conf_threshold, elim_grid_sense=True) #enable \"elim_grid_sense\" by default\n",
        "    #    else:\n",
        "    #        pred_boxes, pred_classes, pred_scores = yolo3_postprocess_np(prediction, image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=conf_threshold, elim_grid_sense=elim_grid_sense)\n",
        "    start = time.time()\n",
        "    pred_boxes, pred_classes, pred_scores = yolo3_postprocess_np(prediction, image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=conf_threshold)#, elim_grid_sense=elim_grid_sense)\n",
        "    print('Time to postprocess prediction',time.time()-start)\n",
        "\n",
        "    return pred_boxes, pred_classes, pred_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1DH5LVpzTcw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def expit(x):\n",
        "\n",
        "    z = np.exp(-x)\n",
        "    sig = 1 / (1 + z)\n",
        "\n",
        "    return sig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb49uAkCzUJA"
      },
      "outputs": [],
      "source": [
        "#from scipy.special import expit\n",
        "\n",
        "def preprocess_image(image, model_input_shape):\n",
        "    \"\"\"\n",
        "    Prepare model input image data with letterbox\n",
        "    resize, normalize and dim expansion\n",
        "    # Arguments\n",
        "        image: origin input image\n",
        "            PIL Image object containing image data\n",
        "        model_input_shape: model input image shape\n",
        "            tuple of format (height, width).\n",
        "    # Returns\n",
        "        image_data: numpy array of image data for model input.\n",
        "    \"\"\"\n",
        "    #resized_image = cv2.resize(image, model_input_shape[::-1], cv2.INTER_AREA)\n",
        "    resized_image = letterbox_resize(image, model_input_shape[::-1])\n",
        "    image_data = np.asarray(resized_image).astype('float32')\n",
        "    image_data = normalize_image(image_data)\n",
        "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
        "    return image_data\n",
        "\n",
        "def letterbox_resize(image, target_size, return_padding_info=False):\n",
        "    \"\"\"\n",
        "    Resize image with unchanged aspect ratio using padding\n",
        "    # Arguments\n",
        "        image: origin image to be resize\n",
        "            PIL Image object containing image data\n",
        "        target_size: target image size,\n",
        "            tuple of format (width, height).\n",
        "        return_padding_info: whether to return padding size & offset info\n",
        "            Boolean flag to control return value\n",
        "    # Returns\n",
        "        new_image: resized PIL Image object.\n",
        "        padding_size: padding image size (keep aspect ratio).\n",
        "            will be used to reshape the ground truth bounding box\n",
        "        offset: top-left offset in target image padding.\n",
        "            will be used to reshape the ground truth bounding box\n",
        "    \"\"\"\n",
        "    src_w, src_h = image.size\n",
        "    target_w, target_h = target_size\n",
        "\n",
        "    # calculate padding scale and padding offset\n",
        "    scale = min(target_w/src_w, target_h/src_h)\n",
        "    padding_w = int(src_w * scale)\n",
        "    padding_h = int(src_h * scale)\n",
        "    padding_size = (padding_w, padding_h)\n",
        "\n",
        "    dx = (target_w - padding_w)//2\n",
        "    dy = (target_h - padding_h)//2\n",
        "    offset = (dx, dy)\n",
        "\n",
        "    # create letterbox resized image\n",
        "    image = image.resize(padding_size, Image.BICUBIC)\n",
        "    new_image = Image.new('RGB', target_size, (128,128,128))\n",
        "    new_image.paste(image, offset)\n",
        "\n",
        "    if return_padding_info:\n",
        "        return new_image, padding_size, offset\n",
        "    else:\n",
        "        return new_image\n",
        "\n",
        "def normalize_image(image):\n",
        "    \"\"\"\n",
        "    normalize image array from 0 ~ 255\n",
        "    to 0.0 ~ 1.0\n",
        "    # Arguments\n",
        "        image: origin input image\n",
        "            numpy image array with dtype=float, 0.0 ~ 255.0\n",
        "    # Returns\n",
        "        image: numpy image array with dtype=float, 0.0 ~ 1.0\n",
        "    \"\"\"\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "\n",
        "    return image\n",
        "\n",
        "def yolo3_postprocess_np(yolo_outputs, image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=0.1, iou_threshold=0.4, elim_grid_sense=False):\n",
        "    # here we sort the prediction tensor list with grid size (e.g. 19/38/76)\n",
        "    # to make sure it matches with anchors order\n",
        "    yolo_outputs.sort(key=lambda x: x.shape[1])\n",
        "    #print(f\"yolo outputs sorted: {yolo_outputs}\")\n",
        "\n",
        "    #print(f\"anchors: {anchors}\")\n",
        "\n",
        "    predictions = yolo3_decode(yolo_outputs, anchors, num_classes, input_shape=model_input_shape, elim_grid_sense=elim_grid_sense)\n",
        "    #print(predictions)\n",
        "    predictions = yolo_correct_boxes(predictions, image_shape, model_input_shape)\n",
        "    #print(predictions)\n",
        "\n",
        "    boxes, classes, scores = yolo_handle_predictions(predictions,\n",
        "                                                     image_shape,\n",
        "                                                     num_classes,\n",
        "                                                     max_boxes=max_boxes,\n",
        "                                                     confidence=confidence,\n",
        "                                                     iou_threshold=iou_threshold)\n",
        "\n",
        "    print(classes, scores)\n",
        "\n",
        "    boxes = yolo_adjust_boxes(boxes, image_shape)\n",
        "    print(boxes)\n",
        "\n",
        "    return boxes, classes, scores\n",
        "\n",
        "def yolo3_decode(predictions, anchors, num_classes, input_shape, elim_grid_sense=False):\n",
        "    \"\"\"\n",
        "    YOLOv3 Head to process predictions from YOLOv3 models\n",
        "    :param num_classes: Total number of classes\n",
        "    :param anchors: YOLO style anchor list for bounding box assignment\n",
        "    :param input_shape: Input shape of the image\n",
        "    :param predictions: A list of three tensors with shape (N, 19, 19, 255), (N, 38, 38, 255) and (N, 76, 76, 255)\n",
        "    :return: A tensor with the shape (N, num_boxes, 85)\n",
        "    \"\"\"\n",
        "    print(f\"predictions length: {len(predictions)}, anchors length: {len(anchors)//3}\")\n",
        "    assert len(predictions) == len(anchors)//3, 'anchor numbers does not match prediction.'\n",
        "\n",
        "    if len(predictions) == 3: # assume 3 set of predictions is YOLOv3\n",
        "        anchor_mask = [[6,7,8], [3,4,5], [0,1,2]]\n",
        "        scale_x_y = [1.05, 1.1, 1.2] if elim_grid_sense else [None, None, None]\n",
        "    elif len(predictions) == 2: # 2 set of predictions is YOLOv3-tiny\n",
        "        anchor_mask = [[3,4,5], [0,1,2]]\n",
        "        scale_x_y = [1.05, 1.05] if elim_grid_sense else [None, None]\n",
        "    else:\n",
        "        raise ValueError('Unsupported prediction length: {}'.format(len(predictions)))\n",
        "\n",
        "    results = []\n",
        "    for i, prediction in enumerate(predictions):\n",
        "        results.append(yolo_decode(prediction, anchors[anchor_mask[i]], num_classes, input_shape, scale_x_y=scale_x_y[i], use_softmax=False))\n",
        "\n",
        "    return np.concatenate(results, axis=1)\n",
        "\n",
        "def yolo_decode(prediction, anchors, num_classes, input_shape, scale_x_y=None, use_softmax=False):\n",
        "    '''Decode final layer features to bounding box parameters.'''\n",
        "    batch_size = np.shape(prediction)[0]\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    grid_shape = np.shape(prediction)[1:3]\n",
        "    #check if stride on height & width are same\n",
        "    assert input_shape[0]//grid_shape[0] == input_shape[1]//grid_shape[1], 'model stride mismatch.'\n",
        "    stride = input_shape[0] // grid_shape[0]\n",
        "\n",
        "    prediction = np.reshape(prediction,\n",
        "                            (batch_size, grid_shape[0] * grid_shape[1] * num_anchors, num_classes + 5))\n",
        "\n",
        "    ################################\n",
        "    # generate x_y_offset grid map\n",
        "    grid_y = np.arange(grid_shape[0])\n",
        "    grid_x = np.arange(grid_shape[1])\n",
        "    x_offset, y_offset = np.meshgrid(grid_x, grid_y)\n",
        "\n",
        "    x_offset = np.reshape(x_offset, (-1, 1))\n",
        "    y_offset = np.reshape(y_offset, (-1, 1))\n",
        "\n",
        "    x_y_offset = np.concatenate((x_offset, y_offset), axis=1)\n",
        "    x_y_offset = np.tile(x_y_offset, (1, num_anchors))\n",
        "    x_y_offset = np.reshape(x_y_offset, (-1, 2))\n",
        "    x_y_offset = np.expand_dims(x_y_offset, 0)\n",
        "\n",
        "    ################################\n",
        "\n",
        "    # Log space transform of the height and width\n",
        "    anchors = np.tile(anchors, (grid_shape[0] * grid_shape[1], 1))\n",
        "    anchors = np.expand_dims(anchors, 0)\n",
        "\n",
        "    if scale_x_y:\n",
        "        # Eliminate grid sensitivity trick involved in YOLOv4\n",
        "        #\n",
        "        # Reference Paper & code:\n",
        "        #     \"YOLOv4: Optimal Speed and Accuracy of Object Detection\"\n",
        "        #     https://arxiv.org/abs/2004.10934\n",
        "        #     https://github.com/opencv/opencv/issues/17148\n",
        "        #\n",
        "        box_xy_tmp = expit(prediction[..., :2]) * scale_x_y - (scale_x_y - 1) / 2\n",
        "        box_xy = (box_xy_tmp + x_y_offset) / np.array(grid_shape)[::-1]\n",
        "    else:\n",
        "        box_xy = (expit(prediction[..., :2]) + x_y_offset) / np.array(grid_shape)[::-1]\n",
        "    box_wh = (np.exp(prediction[..., 2:4]) * anchors) / np.array(input_shape)[::-1]\n",
        "\n",
        "    # Sigmoid objectness scores\n",
        "    objectness = expit(prediction[..., 4])  # p_o (objectness score)\n",
        "    objectness = np.expand_dims(objectness, -1)  # To make the same number of values for axis 0 and 1\n",
        "\n",
        "    if use_softmax:\n",
        "        # Softmax class scores\n",
        "        class_scores = softmax(prediction[..., 5:], axis=-1)\n",
        "    else:\n",
        "        # Sigmoid class scores\n",
        "        class_scores = expit(prediction[..., 5:])\n",
        "\n",
        "    return np.concatenate([box_xy, box_wh, objectness, class_scores], axis=2)\n",
        "\n",
        "def yolo_correct_boxes(predictions, img_shape, model_input_shape):\n",
        "    '''rescale predicition boxes back to original image shape'''\n",
        "    box_xy = predictions[..., :2]\n",
        "    box_wh = predictions[..., 2:4]\n",
        "    objectness = np.expand_dims(predictions[..., 4], -1)\n",
        "    class_scores = predictions[..., 5:]\n",
        "\n",
        "    # model_input_shape & image_shape should be (height, width) format\n",
        "    model_input_shape = np.array(model_input_shape, dtype='float32')\n",
        "    image_shape = np.array(img_shape, dtype='float32')\n",
        "    height, width = image_shape\n",
        "\n",
        "    new_shape = np.round(image_shape * np.min(model_input_shape/image_shape))\n",
        "    offset = (model_input_shape-new_shape)/2./model_input_shape\n",
        "    scale = model_input_shape/new_shape\n",
        "    # reverse offset/scale to match (w,h) order\n",
        "    offset = offset[..., ::-1]\n",
        "    scale = scale[..., ::-1]\n",
        "\n",
        "    box_xy = (box_xy - offset) * scale\n",
        "    box_wh *= scale\n",
        "\n",
        "    # Convert centoids to top left coordinates\n",
        "    box_xy -= box_wh / 2\n",
        "\n",
        "    # Scale boxes back to original image shape.\n",
        "    image_wh = image_shape[..., ::-1]\n",
        "    box_xy *= image_wh\n",
        "    box_wh *= image_wh\n",
        "\n",
        "    return np.concatenate([box_xy, box_wh, objectness, class_scores], axis=2)\n",
        "\n",
        "def yolo_handle_predictions(predictions, image_shape, num_classes, max_boxes=5, confidence=0.1, iou_threshold=0.4, use_cluster_nms=False, use_wbf=False):\n",
        "    boxes = predictions[:, :, :4]\n",
        "    box_confidences = np.expand_dims(predictions[:, :, 4], -1)\n",
        "    box_class_probs = predictions[:, :, 5:]\n",
        "\n",
        "    # check if only 1 class for different score\n",
        "    if num_classes == 1:\n",
        "        box_scores = box_confidences\n",
        "    else:\n",
        "        box_scores = box_confidences * box_class_probs\n",
        "\n",
        "    # filter boxes with score threshold\n",
        "    box_classes = np.argmax(box_scores, axis=-1)\n",
        "    box_class_scores = np.max(box_scores, axis=-1)\n",
        "    pos = np.where(box_class_scores >= confidence)\n",
        "\n",
        "    boxes = boxes[pos]\n",
        "    classes = box_classes[pos]\n",
        "    scores = box_class_scores[pos]\n",
        "\n",
        "    if use_cluster_nms:\n",
        "        # use Fast/Cluster NMS for boxes postprocess\n",
        "        n_boxes, n_classes, n_scores = fast_cluster_nms_boxes(boxes, classes, scores, iou_threshold, confidence=confidence)\n",
        "    elif use_wbf:\n",
        "        # use Weighted-Boxes-Fusion for boxes postprocess\n",
        "        n_boxes, n_classes, n_scores = weighted_boxes_fusion([boxes], [classes], [scores], image_shape, weights=None, iou_thr=iou_threshold)\n",
        "    else:\n",
        "        # Boxes, Classes and Scores returned from NMS\n",
        "        n_boxes, n_classes, n_scores = nms_boxes(boxes, classes, scores, iou_threshold, confidence=confidence)\n",
        "\n",
        "    if n_boxes:\n",
        "        boxes = np.concatenate(n_boxes)\n",
        "        classes = np.concatenate(n_classes).astype('int32')\n",
        "        scores = np.concatenate(n_scores)\n",
        "        boxes, classes, scores = filter_boxes(boxes, classes, scores, max_boxes)\n",
        "\n",
        "        return boxes, classes, scores\n",
        "\n",
        "def yolo_adjust_boxes(boxes, img_shape):\n",
        "    '''\n",
        "    change box format from (x,y,w,h) top left coordinate to\n",
        "    (xmin,ymin,xmax,ymax) format\n",
        "    '''\n",
        "    if boxes is None or len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    image_shape = np.array(img_shape, dtype='float32')\n",
        "    height, width = image_shape\n",
        "\n",
        "    adjusted_boxes = []\n",
        "    for box in boxes:\n",
        "        x, y, w, h = box\n",
        "\n",
        "        xmin = x\n",
        "        ymin = y\n",
        "        xmax = x + w\n",
        "        ymax = y + h\n",
        "\n",
        "        ymin = max(0, np.floor(ymin + 0.5).astype('int32'))\n",
        "        xmin = max(0, np.floor(xmin + 0.5).astype('int32'))\n",
        "        ymax = min(height, np.floor(ymax + 0.5).astype('int32'))\n",
        "        xmax = min(width, np.floor(xmax + 0.5).astype('int32'))\n",
        "        adjusted_boxes.append([xmin,ymin,xmax,ymax])\n",
        "\n",
        "    return np.array(adjusted_boxes,dtype=np.int32)\n",
        "\n",
        "def filter_boxes(boxes, classes, scores, max_boxes):\n",
        "    '''\n",
        "    Sort the prediction boxes according to score\n",
        "    and only pick top \"max_boxes\" ones\n",
        "    '''\n",
        "    # sort result according to scores\n",
        "    sorted_indices = np.argsort(scores)\n",
        "    sorted_indices = sorted_indices[::-1]\n",
        "    nboxes = boxes[sorted_indices]\n",
        "    nclasses = classes[sorted_indices]\n",
        "    nscores = scores[sorted_indices]\n",
        "\n",
        "    # only pick max_boxes\n",
        "    nboxes = nboxes[:max_boxes]\n",
        "    nclasses = nclasses[:max_boxes]\n",
        "    nscores = nscores[:max_boxes]\n",
        "\n",
        "    return nboxes, nclasses, nscores\n",
        "\n",
        "def box_iou(boxes):\n",
        "    \"\"\"\n",
        "    Calculate IoU value of 1st box with other boxes of a box array\n",
        "    Parameters\n",
        "    ----------\n",
        "    boxes: bbox numpy array, shape=(N, 4), xywh\n",
        "           x,y are top left coordinates\n",
        "    Returns\n",
        "    -------\n",
        "    iou: numpy array, shape=(N-1,)\n",
        "         IoU value of boxes[1:] with boxes[0]\n",
        "    \"\"\"\n",
        "    # get box coordinate and area\n",
        "    x = boxes[:, 0]\n",
        "    y = boxes[:, 1]\n",
        "    w = boxes[:, 2]\n",
        "    h = boxes[:, 3]\n",
        "    areas = w * h\n",
        "\n",
        "    # check IoU\n",
        "    inter_xmin = np.maximum(x[1:], x[0])\n",
        "    inter_ymin = np.maximum(y[1:], y[0])\n",
        "    inter_xmax = np.minimum(x[1:] + w[1:], x[0] + w[0])\n",
        "    inter_ymax = np.minimum(y[1:] + h[1:], y[0] + h[0])\n",
        "\n",
        "    inter_w = np.maximum(0.0, inter_xmax - inter_xmin + 1)\n",
        "    inter_h = np.maximum(0.0, inter_ymax - inter_ymin + 1)\n",
        "\n",
        "    inter = inter_w * inter_h\n",
        "    iou = inter / (areas[1:] + areas[0] - inter)\n",
        "    return iou\n",
        "\n",
        "def box_diou(boxes):\n",
        "    \"\"\"\n",
        "    Calculate DIoU value of 1st box with other boxes of a box array\n",
        "    Reference Paper:\n",
        "        \"Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression\"\n",
        "        https://arxiv.org/abs/1911.08287\n",
        "    Parameters\n",
        "    ----------\n",
        "    boxes: bbox numpy array, shape=(N, 4), xywh\n",
        "           x,y are top left coordinates\n",
        "    Returns\n",
        "    -------\n",
        "    diou: numpy array, shape=(N-1,)\n",
        "         IoU value of boxes[1:] with boxes[0]\n",
        "    \"\"\"\n",
        "    # get box coordinate and area\n",
        "    x = boxes[:, 0]\n",
        "    y = boxes[:, 1]\n",
        "    w = boxes[:, 2]\n",
        "    h = boxes[:, 3]\n",
        "    areas = w * h\n",
        "\n",
        "    # check IoU\n",
        "    inter_xmin = np.maximum(x[1:], x[0])\n",
        "    inter_ymin = np.maximum(y[1:], y[0])\n",
        "    inter_xmax = np.minimum(x[1:] + w[1:], x[0] + w[0])\n",
        "    inter_ymax = np.minimum(y[1:] + h[1:], y[0] + h[0])\n",
        "\n",
        "    inter_w = np.maximum(0.0, inter_xmax - inter_xmin + 1)\n",
        "    inter_h = np.maximum(0.0, inter_ymax - inter_ymin + 1)\n",
        "\n",
        "    inter = inter_w * inter_h\n",
        "    iou = inter / (areas[1:] + areas[0] - inter)\n",
        "\n",
        "    # box center distance\n",
        "    x_center = x + w/2\n",
        "    y_center = y + h/2\n",
        "    center_distance = np.power(x_center[1:] - x_center[0], 2) + np.power(y_center[1:] - y_center[0], 2)\n",
        "\n",
        "    # get enclosed area\n",
        "    enclose_xmin = np.minimum(x[1:], x[0])\n",
        "    enclose_ymin = np.minimum(y[1:], y[0])\n",
        "    enclose_xmax = np.maximum(x[1:] + w[1:], x[0] + w[0])\n",
        "    enclose_ymax = np.maximum(x[1:] + w[1:], x[0] + w[0])\n",
        "    enclose_w = np.maximum(0.0, enclose_xmax - enclose_xmin + 1)\n",
        "    enclose_h = np.maximum(0.0, enclose_ymax - enclose_ymin + 1)\n",
        "    # get enclosed diagonal distance\n",
        "    enclose_diagonal = np.power(enclose_w, 2) + np.power(enclose_h, 2)\n",
        "    # calculate DIoU, add epsilon in denominator to avoid dividing by 0\n",
        "    diou = iou - 1.0 * (center_distance) / (enclose_diagonal + np.finfo(float).eps)\n",
        "\n",
        "    return diou\n",
        "\n",
        "def nms_boxes(boxes, classes, scores, iou_threshold, confidence=0.1, use_diou=True, is_soft=False, use_exp=False, sigma=0.5):\n",
        "    nboxes, nclasses, nscores = [], [], []\n",
        "    for c in set(classes):\n",
        "        # handle data for one class\n",
        "        inds = np.where(classes == c)\n",
        "        b = boxes[inds]\n",
        "        c = classes[inds]\n",
        "        s = scores[inds]\n",
        "\n",
        "        # make a data copy to avoid breaking\n",
        "        # during nms operation\n",
        "        b_nms = copy.deepcopy(b)\n",
        "        c_nms = copy.deepcopy(c)\n",
        "        s_nms = copy.deepcopy(s)\n",
        "\n",
        "        while len(s_nms) > 0:\n",
        "            # pick the max box and store, here\n",
        "            # we also use copy to persist result\n",
        "            i = np.argmax(s_nms, axis=-1)\n",
        "            nboxes.append(copy.deepcopy(b_nms[i]))\n",
        "            nclasses.append(copy.deepcopy(c_nms[i]))\n",
        "            nscores.append(copy.deepcopy(s_nms[i]))\n",
        "\n",
        "            # swap the max line and first line\n",
        "            b_nms[[i,0],:] = b_nms[[0,i],:]\n",
        "            c_nms[[i,0]] = c_nms[[0,i]]\n",
        "            s_nms[[i,0]] = s_nms[[0,i]]\n",
        "\n",
        "            if use_diou:\n",
        "                iou = box_diou(b_nms)\n",
        "                #iou = box_diou_matrix(b_nms, b_nms)[0][1:]\n",
        "            else:\n",
        "                iou = box_iou(b_nms)\n",
        "                #iou = box_iou_matrix(b_nms, b_nms)[0][1:]\n",
        "\n",
        "            # drop the last line since it has been record\n",
        "            b_nms = b_nms[1:]\n",
        "            c_nms = c_nms[1:]\n",
        "            s_nms = s_nms[1:]\n",
        "\n",
        "            if is_soft:\n",
        "                # Soft-NMS\n",
        "                if use_exp:\n",
        "                    # score refresh formula:\n",
        "                    # score = score * exp(-(iou^2)/sigma)\n",
        "                    s_nms = s_nms * np.exp(-(iou * iou) / sigma)\n",
        "                else:\n",
        "                    # score refresh formula:\n",
        "                    # score = score * (1 - iou) if iou > threshold\n",
        "                    depress_mask = np.where(iou > iou_threshold)[0]\n",
        "                    s_nms[depress_mask] = s_nms[depress_mask]*(1-iou[depress_mask])\n",
        "                keep_mask = np.where(s_nms >= confidence)[0]\n",
        "            else:\n",
        "                # normal Hard-NMS\n",
        "                keep_mask = np.where(iou <= iou_threshold)[0]\n",
        "\n",
        "            # keep needed box for next loop\n",
        "            b_nms = b_nms[keep_mask]\n",
        "            c_nms = c_nms[keep_mask]\n",
        "            s_nms = s_nms[keep_mask]\n",
        "\n",
        "    # reformat result for output\n",
        "    nboxes = [np.array(nboxes)]\n",
        "    nclasses = [np.array(nclasses)]\n",
        "    nscores = [np.array(nscores)]\n",
        "    return nboxes, nclasses, nscores\n",
        "\n",
        "def get_weighted_box(boxes, conf_type='avg'):\n",
        "    \"\"\"\n",
        "    Create weighted box for set of boxes\n",
        "    :param boxes: set of boxes to fuse\n",
        "    :param conf_type: type of confidence one of 'avg' or 'max'\n",
        "    :return: weighted box\n",
        "    \"\"\"\n",
        "\n",
        "    box = np.zeros(6, dtype=np.float32)\n",
        "    conf = 0\n",
        "    conf_list = []\n",
        "    for b in boxes:\n",
        "        box[2:] += (b[1] * b[2:])\n",
        "        conf += b[1]\n",
        "        conf_list.append(b[1])\n",
        "    box[0] = boxes[0][0]\n",
        "    if conf_type == 'avg':\n",
        "        box[1] = conf / len(boxes)\n",
        "    elif conf_type == 'max':\n",
        "        box[1] = np.array(conf_list).max()\n",
        "    box[2:] /= conf\n",
        "    return box\n",
        "\n",
        "def bb_intersection_over_union(A, B) -> float:\n",
        "    xA = max(A[0], B[0])\n",
        "    yA = max(A[1], B[1])\n",
        "    xB = min(A[2], B[2])\n",
        "    yB = min(A[3], B[3])\n",
        "\n",
        "    # compute the area of intersection rectangle\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "\n",
        "    if interArea == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # compute the area of both the prediction and ground-truth rectangles\n",
        "    boxAArea = (A[2] - A[0]) * (A[3] - A[1])\n",
        "    boxBArea = (B[2] - B[0]) * (B[3] - B[1])\n",
        "\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "    return iou\n",
        "\n",
        "def find_matching_box(boxes_list, new_box, match_iou):\n",
        "    best_iou = match_iou\n",
        "    best_index = -1\n",
        "    for i in range(len(boxes_list)):\n",
        "        box = boxes_list[i]\n",
        "        if box[0] != new_box[0]:\n",
        "            continue\n",
        "        iou = bb_intersection_over_union(box[2:], new_box[2:])\n",
        "        if iou > best_iou:\n",
        "            best_index = i\n",
        "            best_iou = iou\n",
        "\n",
        "    return best_index, best_iou\n",
        "\n",
        "def prefilter_boxes(boxes, scores, labels, image_shape, weights, thr):\n",
        "    # Create dict with boxes stored by its label\n",
        "    new_boxes = dict()\n",
        "    height, width = image_shape\n",
        "\n",
        "    for t in range(len(boxes)):\n",
        "\n",
        "        if len(boxes[t]) != len(scores[t]):\n",
        "            print('Error. Length of boxes arrays not equal to length of scores array: {} != {}'.format(len(boxes[t]), len(scores[t])))\n",
        "            exit()\n",
        "\n",
        "        if len(boxes[t]) != len(labels[t]):\n",
        "            print('Error. Length of boxes arrays not equal to length of labels array: {} != {}'.format(len(boxes[t]), len(labels[t])))\n",
        "            exit()\n",
        "\n",
        "        for j in range(len(boxes[t])):\n",
        "            score = scores[t][j]\n",
        "            if score < thr:\n",
        "                continue\n",
        "            label = int(labels[t][j])\n",
        "            box_part = boxes[t][j]\n",
        "\n",
        "            # input boxes in raw (x,y,w,h) format,\n",
        "            # convert to normalized (x1,y1,x2,y2)\n",
        "            x1 = max(0, float(box_part[0]) / width)\n",
        "            y1 = max(0, float(box_part[1]) / height)\n",
        "            x2 = min(1, float(box_part[2] + box_part[0]) / width)\n",
        "            y2 = min(1, float(box_part[3] + box_part[1]) / height)\n",
        "\n",
        "            # Box data checks\n",
        "            #if x2 < x1:\n",
        "                #warnings.warn('X2 < X1 value in box. Swap them.')\n",
        "                #x1, x2 = x2, x1\n",
        "            #if y2 < y1:\n",
        "                #warnings.warn('Y2 < Y1 value in box. Swap them.')\n",
        "                #y1, y2 = y2, y1\n",
        "            #if x1 < 0:\n",
        "                #warnings.warn('X1 < 0 in box. Set it to 0.')\n",
        "                #x1 = 0\n",
        "            #if x1 > 1:\n",
        "                #warnings.warn('X1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
        "                #x1 = 1\n",
        "            #if x2 < 0:\n",
        "                #warnings.warn('X2 < 0 in box. Set it to 0.')\n",
        "                #x2 = 0\n",
        "            #if x2 > 1:\n",
        "                #warnings.warn('X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
        "                #x2 = 1\n",
        "            #if y1 < 0:\n",
        "                #warnings.warn('Y1 < 0 in box. Set it to 0.')\n",
        "                #y1 = 0\n",
        "            #if y1 > 1:\n",
        "                #warnings.warn('Y1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
        "                #y1 = 1\n",
        "            #if y2 < 0:\n",
        "                #warnings.warn('Y2 < 0 in box. Set it to 0.')\n",
        "                #y2 = 0\n",
        "            #if y2 > 1:\n",
        "                #warnings.warn('Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
        "                #y2 = 1\n",
        "            if (x2 - x1) * (y2 - y1) == 0.0:\n",
        "                warnings.warn(\"Zero area box skipped: {}.\".format(box_part))\n",
        "                continue\n",
        "\n",
        "            b = [int(label), float(score) * weights[t], x1, y1, x2, y2]\n",
        "            if label not in new_boxes:\n",
        "                new_boxes[label] = []\n",
        "            new_boxes[label].append(b)\n",
        "\n",
        "    # Sort each list in dict by score and transform it to numpy array\n",
        "    for k in new_boxes:\n",
        "        current_boxes = np.array(new_boxes[k])\n",
        "        new_boxes[k] = current_boxes[current_boxes[:, 1].argsort()[::-1]]\n",
        "\n",
        "    return new_boxes\n",
        "\n",
        "def weighted_boxes_fusion(boxes_list, labels_list, scores_list, image_shape, weights=None, iou_thr=0.55, skip_box_thr=0.0, conf_type='avg', allows_overflow=False):\n",
        "    '''\n",
        "    :param boxes_list: list of boxes predictions from each model, each box is 4 numbers.\n",
        "    It has 3 dimensions (models_number, model_preds, 4)\n",
        "    Order of boxes: x1, y1, x2, y2. We expect float normalized coordinates [0; 1]\n",
        "    :param scores_list: list of scores for each model\n",
        "    :param labels_list: list of labels for each model\n",
        "    :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n",
        "    :param iou_thr: IoU value for boxes to be a match\n",
        "    :param skip_box_thr: exclude boxes with score lower than this variable\n",
        "    :param conf_type: how to calculate confidence in weighted boxes. 'avg': average value, 'max': maximum value\n",
        "    :param allows_overflow: false if we want confidence score not exceed 1.0\n",
        "    :return: boxes: boxes coordinates (Order of boxes: x1, y1, x2, y2).\n",
        "    :return: scores: confidence scores\n",
        "    :return: labels: boxes labels\n",
        "    '''\n",
        "\n",
        "    if weights is None:\n",
        "        weights = np.ones(len(boxes_list))\n",
        "    if len(weights) != len(boxes_list):\n",
        "        print('Warning: incorrect number of weights {}. Must be: {}. Set weights equal to 1.'.format(len(weights), len(boxes_list)))\n",
        "        weights = np.ones(len(boxes_list))\n",
        "    weights = np.array(weights)\n",
        "\n",
        "    if conf_type not in ['avg', 'max']:\n",
        "        print('Unknown conf_type: {}. Must be \"avg\" or \"max\"'.format(conf_type))\n",
        "        exit()\n",
        "\n",
        "    image_shape = np.array(image_shape, dtype='float32')\n",
        "    filtered_boxes = prefilter_boxes(boxes_list, scores_list, labels_list, image_shape, weights, skip_box_thr)\n",
        "    if len(filtered_boxes) == 0:\n",
        "        return np.zeros((0, 4)), np.zeros((0,)), np.zeros((0,))\n",
        "\n",
        "    overall_boxes = []\n",
        "    for label in filtered_boxes:\n",
        "        boxes = filtered_boxes[label]\n",
        "        new_boxes = []\n",
        "        weighted_boxes = []\n",
        "\n",
        "        # Clusterize boxes\n",
        "        for j in range(0, len(boxes)):\n",
        "            index, best_iou = find_matching_box(weighted_boxes, boxes[j], iou_thr)\n",
        "            if index != -1:\n",
        "                new_boxes[index].append(boxes[j])\n",
        "                weighted_boxes[index] = get_weighted_box(new_boxes[index], conf_type)\n",
        "            else:\n",
        "                new_boxes.append([boxes[j].copy()])\n",
        "                weighted_boxes.append(boxes[j].copy())\n",
        "\n",
        "        # Rescale confidence based on number of models and boxes\n",
        "        for i in range(len(new_boxes)):\n",
        "            if not allows_overflow:\n",
        "                weighted_boxes[i][1] = weighted_boxes[i][1] * min(weights.sum(), len(new_boxes[i])) / weights.sum()\n",
        "            else:\n",
        "                weighted_boxes[i][1] = weighted_boxes[i][1] * len(new_boxes[i]) / weights.sum()\n",
        "        overall_boxes.append(np.array(weighted_boxes))\n",
        "\n",
        "    overall_boxes = np.concatenate(overall_boxes, axis=0)\n",
        "    overall_boxes = overall_boxes[overall_boxes[:, 1].argsort()[::-1]]\n",
        "    boxes = overall_boxes[:, 2:]\n",
        "    scores = overall_boxes[:, 1]\n",
        "    labels = overall_boxes[:, 0]\n",
        "\n",
        "    # convert boxes back to (x,y,w,h)\n",
        "    boxes[..., 2:] = boxes[..., 2:] - boxes[..., :2]\n",
        "    # Scale boxes back to original image shape.\n",
        "    image_wh = image_shape[..., ::-1]\n",
        "    boxes[..., :2] *= image_wh\n",
        "    boxes[..., 2:] *= image_wh\n",
        "\n",
        "    return [boxes], [labels], [scores]\n",
        "\n",
        "def fast_cluster_nms_boxes(boxes, classes, scores, iou_threshold, confidence=0.1, use_cluster=True, use_diou=True, use_weighted=True, use_matrix_nms=False, use_spm=False):\n",
        "    \"\"\"\n",
        "    Fast NMS/Cluster NMS/Matrix NMS bbox post process\n",
        "    Reference Paper:\n",
        "        1. \"YOLACT: Real-time Instance Segmentation\"\n",
        "           https://arxiv.org/abs/1904.02689\n",
        "        2. \"Enhancing Geometric Factors in Model Learning and Inference for Object Detection and Instance Segmentation\"\n",
        "           https://arxiv.org/abs/2005.03572\n",
        "        3. \"SOLOv2: Dynamic, Faster and Stronger\"\n",
        "           https://arxiv.org/abs/2003.10152\n",
        "        4. Blogpost on zhihu:\n",
        "           https://zhuanlan.zhihu.com/p/157900024\n",
        "    Parameters\n",
        "    ----------\n",
        "    boxes:   bbox numpy array, shape=(N, 4), xywh\n",
        "             x,y are top left coordinates\n",
        "    classes: bbox class index numpy array, shape=(N, 1)\n",
        "    scores:  bbox score numpy array, shape=(N, 1)\n",
        "    iou_threshold:\n",
        "    Returns\n",
        "    -------\n",
        "    nboxes:   NMSed bbox numpy array, shape=(N, 4), xywh\n",
        "              x,y are top left coordinates\n",
        "    nclasses: NMSed bbox class index numpy array, shape=(N, 1)\n",
        "    nscores:  NMSed bbox score numpy array, shape=(N, 1)\n",
        "    \"\"\"\n",
        "    nboxes, nclasses, nscores = [], [], []\n",
        "    for c in set(classes):\n",
        "        # handle data for one class\n",
        "        inds = np.where(classes == c)\n",
        "        b = boxes[inds]\n",
        "        c = classes[inds]\n",
        "        s = scores[inds]\n",
        "\n",
        "        # make a data copy to avoid breaking\n",
        "        # during nms operation\n",
        "        b_nms = copy.deepcopy(b)\n",
        "        c_nms = copy.deepcopy(c)\n",
        "        s_nms = copy.deepcopy(s)\n",
        "\n",
        "        # ascend sort boxes according to scores\n",
        "        sorted_indices = np.argsort(s_nms)\n",
        "        sorted_indices = sorted_indices[::-1]\n",
        "        b_nms = b_nms[sorted_indices]\n",
        "        c_nms = c_nms[sorted_indices]\n",
        "        s_nms = s_nms[sorted_indices]\n",
        "\n",
        "        # number of boxes for one class\n",
        "        num_boxes = b_nms.shape[0]\n",
        "\n",
        "        # get IoU/DIoU matrix (upper triangular matrix)\n",
        "        if use_diou:\n",
        "            iou_matrix = box_diou_matrix(b_nms, b_nms)\n",
        "        else:\n",
        "            iou_matrix = box_iou_matrix(b_nms, b_nms)\n",
        "        iou_matrix = np.triu(iou_matrix, k=1)\n",
        "        max_iou = np.max(iou_matrix, axis=0)\n",
        "        updated_iou_matrix = copy.deepcopy(iou_matrix)\n",
        "\n",
        "        # Cluster loop\n",
        "        if use_cluster:\n",
        "            for i in range(200):\n",
        "                prev_iou_matrix = copy.deepcopy(updated_iou_matrix)\n",
        "                max_iou = np.max(prev_iou_matrix, axis=0)\n",
        "                keep_diag = np.diag((max_iou < iou_threshold).astype(np.float32))\n",
        "                updated_iou_matrix = np.dot(keep_diag, iou_matrix)\n",
        "                if (prev_iou_matrix == updated_iou_matrix).all():\n",
        "                    break\n",
        "\n",
        "        if use_matrix_nms:\n",
        "            # Matrix NMS\n",
        "            max_iou_expand = np.tile(max_iou, (num_boxes, 1)).T  #(num_boxes)x(num_boxes)\n",
        "\n",
        "            def get_decay_factor(method='gauss', sigma=0.5):\n",
        "                if method == 'gauss':\n",
        "                    # gaussian decay\n",
        "                    decay_factor = np.exp(-(iou_matrix**2 - max_iou_expand**2) / sigma)\n",
        "                else:\n",
        "                    # linear decay\n",
        "                    decay_factor = (1 - iou_matrix) / (1 - max_iou_expand)\n",
        "\n",
        "                # decay factor: 1xN\n",
        "                decay_factor = np.min(decay_factor, axis=0)\n",
        "                # clamp decay factor to <= 1\n",
        "                decay_factor = np.minimum(decay_factor, 1.0)\n",
        "                return decay_factor\n",
        "\n",
        "            # decay factor for box score\n",
        "            decay_factor = get_decay_factor()\n",
        "\n",
        "            # apply decay factor to punish box score,\n",
        "            # and filter box with confidence threshold\n",
        "            s_matrix_decay = s_nms * decay_factor\n",
        "            keep_mask = s_matrix_decay >= confidence\n",
        "\n",
        "        elif use_spm:\n",
        "            # apply SPM(Score Penalty Mechanism)\n",
        "            if use_diou:\n",
        "                # TODO: Cluster SPM distance NMS couldn't achieve good result, may need to double check\n",
        "                # currently we fallback to normal SPM\n",
        "                #\n",
        "                # Reference:\n",
        "                # https://github.com/Zzh-tju/CIoU/blob/master/layers/functions/detection.py\n",
        "                # https://zhuanlan.zhihu.com/p/157900024\n",
        "\n",
        "                #diou_matrix = box_diou_matrix(b_nms, b_nms)\n",
        "                #flag = (updated_iou_matrix >= 0).astype(np.float32)\n",
        "                #penalty_coef = np.prod(np.minimum(np.exp(-(updated_iou_matrix**2)/0.2) + diou_matrix*((updated_iou_matrix>0).astype(np.float32)), flag), axis=0)\n",
        "                penalty_coef = np.prod(np.exp(-(updated_iou_matrix**2)/0.2), axis=0)\n",
        "            else:\n",
        "                penalty_coef = np.prod(np.exp(-(updated_iou_matrix**2)/0.2), axis=0)\n",
        "            s_spm = penalty_coef * s_nms\n",
        "            keep_mask = s_spm >= confidence\n",
        "\n",
        "        else:\n",
        "            # filter low score box with iou_threshold\n",
        "            keep_mask = max_iou < iou_threshold\n",
        "\n",
        "        if use_weighted:\n",
        "            # generate weights matrix with box score and final IoU matrix\n",
        "            weights = (updated_iou_matrix*(updated_iou_matrix>iou_threshold).astype(np.float32) + np.eye(num_boxes)) * (s_nms.reshape((1, num_boxes)))\n",
        "\n",
        "            # convert box format to (xmin,ymin,xmax,ymax) for weighted average,\n",
        "            # and expand to NxN array\n",
        "            xmin_expand = np.tile(b_nms[:,0], (num_boxes, 1))  #(num_boxes)x(num_boxes)\n",
        "            ymin_expand = np.tile(b_nms[:,1], (num_boxes, 1))  #(num_boxes)x(num_boxes)\n",
        "            xmax_expand = np.tile(b_nms[:,0]+b_nms[:,2], (num_boxes, 1))  #(num_boxes)x(num_boxes)\n",
        "            ymax_expand = np.tile(b_nms[:,1]+b_nms[:,3], (num_boxes, 1))  #(num_boxes)x(num_boxes)\n",
        "\n",
        "            # apply weighted average to all the candidate boxes\n",
        "            weightsum = weights.sum(axis=1)\n",
        "            xmin_expand = np.true_divide((xmin_expand*weights).sum(axis=1), weightsum)\n",
        "            ymin_expand = np.true_divide((ymin_expand*weights).sum(axis=1), weightsum)\n",
        "            xmax_expand = np.true_divide((xmax_expand*weights).sum(axis=1), weightsum)\n",
        "            ymax_expand = np.true_divide((ymax_expand*weights).sum(axis=1), weightsum)\n",
        "\n",
        "            # stack the weighted average boxes and convert back to (x,y,w,h)\n",
        "            b_nms = np.stack([xmin_expand, ymin_expand, xmax_expand-xmin_expand, ymax_expand-ymin_expand], axis=1)\n",
        "\n",
        "        # keep NMSed boxes\n",
        "        b_nms = b_nms[keep_mask]\n",
        "        c_nms = c_nms[keep_mask]\n",
        "        s_nms = s_nms[keep_mask]\n",
        "\n",
        "        # merge NMSed boxes to final result\n",
        "        if len(nboxes) == 0:\n",
        "            nboxes = np.asarray(copy.deepcopy(b_nms))\n",
        "            nclasses = np.asarray(copy.deepcopy(c_nms))\n",
        "            nscores = np.asarray(copy.deepcopy(s_nms))\n",
        "        else:\n",
        "            nboxes = np.append(nboxes, copy.deepcopy(b_nms), axis=0)\n",
        "            nclasses = np.append(nclasses, copy.deepcopy(c_nms), axis=0)\n",
        "            nscores = np.append(nscores, copy.deepcopy(s_nms), axis=0)\n",
        "\n",
        "    # reformat result for output\n",
        "    nboxes = [np.array(nboxes)]\n",
        "    nclasses = [np.array(nclasses)]\n",
        "    nscores = [np.array(nscores)]\n",
        "    return nboxes, nclasses, nscores\n",
        "\n",
        "def box_iou_matrix(boxes1, boxes2):\n",
        "    \"\"\"\n",
        "    Calculate IoU matrix for two box array.\n",
        "    Both sets of boxes are expected to be in (x, y, w, h) format.\n",
        "    Reference implementation:\n",
        "        https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n",
        "    Arguments:\n",
        "        boxes1 (np.array[N, 4])\n",
        "        boxes2 (np.array[M, 4])\n",
        "    Returns:\n",
        "        iou (np.array[N, M]): the NxM matrix containing the pairwise\n",
        "            IoU values for every element in boxes1 and boxes2\n",
        "    \"\"\"\n",
        "\n",
        "    def box_area(box):\n",
        "        # box = 4xN\n",
        "        return box[2] * box[3]\n",
        "\n",
        "    area1 = box_area(boxes1.T)\n",
        "    area2 = box_area(boxes2.T)\n",
        "\n",
        "    inter_min = np.maximum(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n",
        "    inter_max = np.minimum(boxes1[:, None, :2]+boxes1[:, None, 2:], boxes2[:, :2]+boxes2[:, 2:])  # [N,M,2]\n",
        "    inter = np.maximum(inter_max - inter_min, 0).prod(axis=-1)  # [N,M]\n",
        "\n",
        "    iou = inter / (area1[:, None] + area2 - inter)  # iou = inter / (area1 + area2 - inter)\n",
        "    return iou\n",
        "\n",
        "def box_diou_matrix(boxes1, boxes2):\n",
        "    \"\"\"\n",
        "    Calculate DIoU matrix for two box array.\n",
        "    Both sets of boxes are expected to be in (x, y, w, h) format.\n",
        "    Arguments:\n",
        "        boxes1 (np.array[N, 4])\n",
        "        boxes2 (np.array[M, 4])\n",
        "    Returns:\n",
        "        diou (np.array[N, M]): the NxM matrix containing the pairwise\n",
        "            IoU values for every element in boxes1 and boxes2\n",
        "    \"\"\"\n",
        "    iou = box_iou_matrix(boxes1, boxes2)\n",
        "\n",
        "    # box center distance\n",
        "    center_distance = (boxes1[:, None, :2]+boxes1[:, None, 2:]/2) - (boxes2[:, :2]+boxes2[:, 2:]/2)  # [N,M,2]\n",
        "    center_distance = np.power(center_distance[..., 0], 2) + np.power(center_distance[..., 1], 2)  # [N,M]\n",
        "\n",
        "    # get enclosed area\n",
        "    enclose_min = np.minimum(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n",
        "    enclose_max = np.maximum(boxes1[:, None, :2]+boxes1[:, None, 2:], boxes2[:, :2]+boxes2[:, 2:])  # [N,M,2]\n",
        "\n",
        "    enclose_wh = np.maximum(enclose_max - enclose_min, 0) # [N,M,2]\n",
        "    enclose_wh = np.maximum(enclose_max - enclose_min, 0) # [N,M,2]\n",
        "\n",
        "    # get enclosed diagonal distance matrix\n",
        "    enclose_diagonal = np.power(enclose_wh[..., 0], 2) + np.power(enclose_wh[..., 1], 2)  # [N,M]\n",
        "\n",
        "    # calculate DIoU, add epsilon in denominator to avoid dividing by 0\n",
        "    diou = iou - 1.0 * np.true_divide(center_distance, enclose_diagonal + np.finfo(float).eps)\n",
        "\n",
        "    return diou\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZW-xUAyzaeq"
      },
      "outputs": [],
      "source": [
        "def yolo_predict_keras(model, image, anchors, num_classes, model_input_shape, conf_threshold, elim_grid_sense):#, v5_decode):\n",
        "    image_data = preprocess_image(image, model_input_shape)\n",
        "    #origin image shape, in (height, width) format\n",
        "    image_shape = image.size[::-1]\n",
        "\n",
        "    prediction = model.predict([image_data])\n",
        "    if type(prediction) is not list:\n",
        "        prediction = [prediction]\n",
        "\n",
        "#    if len(anchors) == 5:\n",
        "#        # YOLOv2 use 5 anchors\n",
        "#        pred_boxes, pred_classes, pred_scores = yolo2_postprocess_np(prediction[0], image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=conf_threshold, elim_grid_sense=elim_grid_sense)\n",
        "#    else:\n",
        "#        if v5_decode:\n",
        "#            pred_boxes, pred_classes, pred_scores = yolo5_postprocess_np(prediction, image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=conf_threshold, elim_grid_sense=True) #enable \"elim_grid_sense\" by default\n",
        "#        else:\n",
        "#            pred_boxes, pred_classes, pred_scores = yolo3_postprocess_np(prediction, image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=conf_threshold, elim_grid_sense=elim_grid_sense)\n",
        "    pred_boxes, pred_classes, pred_scores = yolo3_postprocess_np(prediction, image_shape, anchors, num_classes, model_input_shape, max_boxes=100, confidence=conf_threshold, elim_grid_sense=elim_grid_sense)\n",
        "\n",
        "    return pred_boxes, pred_classes, pred_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omd2FJnFziFo"
      },
      "outputs": [],
      "source": [
        "def plot_images(image_path, annotation_file):\n",
        "    \"\"\"\n",
        "    Plots the ground truth and prediction for a given image.\n",
        "\n",
        "    Parameters:\n",
        "    - image_path (str): path to the image\n",
        "    - annotation_file (str): path to the annotation file\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    # Read the annotation file\n",
        "    with open(annotation_file, 'r') as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    # Check if the image is in the annotations file\n",
        "    for line in annotations:\n",
        "        if image_path in line:\n",
        "            # Extract the ground truth boxes\n",
        "            ground_truth_boxes = line.split(' ')[1:]\n",
        "            break\n",
        "    else:\n",
        "        print(f\"{image_path} not found in {annotation_file}.\")\n",
        "        return\n",
        "\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Plot the ground truth boxes on the image\n",
        "    for box in ground_truth_boxes:\n",
        "        xmin, ymin, xmax, ymax = list(map(int, box.split(',')))[:-1]\n",
        "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
        "\n",
        "    # Get the prediction for the image\n",
        "    img = Image.open(image_path)\n",
        "    anchors = get_anchors('/content/drive/MyDrive/RabbitHole/keras-YOLOv3-model-set/configs/yolo3_anchors.txt')\n",
        "    num_classes = 7\n",
        "    conf_threshold = 0.4\n",
        "    model_input_shape = (416,416)\n",
        "    pred_boxes, pred_classes, pred_scores = yolo_predict_keras(model, img, anchors, num_classes, model_input_shape, conf_threshold, elim_grid_sense=False)\n",
        "\n",
        "    # Plot the ground truth boxes on the image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    for box in pred_boxes:\n",
        "      xmin, ymin, xmax, ymax = box\n",
        "      cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
        "\n",
        "    # Plot the images\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15, 10))\n",
        "    ax[0].imshow(image)\n",
        "    ax[0].set_title(f\"Ground truth ({os.path.basename(image_path)})\")\n",
        "    ax[1].imshow(img)\n",
        "    ax[1].set_title(f\"Prediction ({os.path.basename(image_path)})\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxyOhmw72OSg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rwEUZ0YJzlrV",
        "outputId": "220e7ae9-8e3d-4c39-a18c-38f7782b0f46"
      },
      "outputs": [],
      "source": [
        "images = [\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_1/frame_s1_11.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_1148.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_617.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_905.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_1105.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_581.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_4/frame_s4_195.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_401.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_48.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_193.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_146.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_4/frame_s4_55.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_4/frame_s4_116.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_709.jpg\",\n",
        "    \"/content/drive/MyDrive/RabbitHole/data/sequence_3/frame_s3_205.jpg\"\n",
        "    ]\n",
        "annotation_file = '/content/drive/MyDrive/RabbitHole/data/annotations.txt'\n",
        "\n",
        "# load model\n",
        "model, format = load_eval_model('/content/drive/MyDrive/RabbitHole/output/yolo3_mobilenet_lite/yolo3_mobilenet_lite.h5')\n",
        "\n",
        "for image_path in images:\n",
        "  plot_images(image_path, annotation_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfpqeXBq0bgX",
        "outputId": "409d5ff8-261d-456c-e25f-b710c30eb27b"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/RabbitHole/keras-YOLOv3-model-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtUT5NOLLmme",
        "outputId": "67a5cb30-d73e-48e3-b2dc-cdd04935182e"
      },
      "outputs": [],
      "source": [
        "!python eval.py \\\n",
        "--model_path=/content/drive/MyDrive/RabbitHole/output/yolo3_mobilenet_lite/yolo3_mobilenet_lite.h5 \\\n",
        "--anchors_path=configs/yolo3_anchors.txt \\\n",
        "--classes_path=/content/drive/MyDrive/RabbitHole/data/classes.txt \\\n",
        "--model_input_shape=416x416 \\\n",
        "--eval_type=VOC \\\n",
        "--iou_threshold=0.5 \\\n",
        "--conf_threshold=0.3 \\\n",
        "--annotation_file=/content/drive/MyDrive/RabbitHole/data/valid.txt \\\n",
        "--save_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ibIwwmcca-u"
      },
      "source": [
        "# LISTA DE AFAZERES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG94fTGKbkmQ"
      },
      "source": [
        "\n",
        "\n",
        "*   Melhorar o Codigo pq pelamor de deus\n",
        "*   Colocar o codigo do Cleber\n",
        "*   Fazer os dois Funcionarem juntos.\n",
        "*   Fazer a Camera lá funcionar com essa Ai\n",
        "*   Fazer um docker para receber imagem e polir ela com CUDA\n",
        "*   Servidooor (uhuul)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
